{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import findspark\n",
    "import boto3\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class ExplodeJson:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.partition = config.__getitem__('partition')\n",
    "        self.partitionReferenceColumn = config.__getitem__('partitionReferenceColumn')\n",
    "        self.idTable = config.__getitem__('idTable')\n",
    "        self.principalTableName = config.__getitem__('principalTableName')\n",
    "        self.listTable = []\n",
    "        self.listRefineTables = []\n",
    "        self._regex = '[^a-zA-Z0-9_-]'\n",
    "\n",
    "    def recursiveParseJson(self,_json):\n",
    "        def parseJson(_json,listJson=[]):\n",
    "            try:\n",
    "                index = 0\n",
    "                items = []\n",
    "                if len(listJson) == 0:\n",
    "                    for item in _json:\n",
    "                        for k, v in item.items():\n",
    "                            if type(v) == list or type(v) == dict:\n",
    "                                if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                    items.append((item[self.idTable],index,re.sub(self._regex, '', k),v,item[self.partitionReferenceColumn]))\n",
    "                                else:\n",
    "                                    items.append((item[self.idTable],index,re.sub(self._regex, '', k),v))\n",
    "\n",
    "                        if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                            item[self.partition] = item[self.partitionReferenceColumn]\n",
    "\n",
    "                        index = index + 1\n",
    "\n",
    "                    for it in items:\n",
    "                        _json[it[1]].pop(it[2])\n",
    "\n",
    "                    self.listTable.append((self.principalTableName,_json))\n",
    "\n",
    "                    if len(items) > 0:\n",
    "                        parseJson(None,items)\n",
    "                else:\n",
    "                    for lj in listJson:\n",
    "                        j = lj[3]\n",
    "                        nj = {}\n",
    "                        if type(j) == dict:\n",
    "                            j[self.idTable] = lj[0]\n",
    "                            for k, v in j.items():\n",
    "                                if type(v) == list or type(v) == dict:\n",
    "                                    if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                        items.append((lj[0],None,re.sub(self._regex, '', k),v,lj[4]))\n",
    "                                    else:\n",
    "                                        items.append((lj[0],index,re.sub(self._regex, '', k),v))\n",
    "                                    if type(v) == list:\n",
    "                                        parseJson(None,items)\n",
    "                                else:\n",
    "                                    nj[re.sub(self._regex, '', k)]=v\n",
    "                                    if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                            nj[self.partition] = lj[4]\n",
    "\n",
    "                            self.listTable.append((lj[2],nj))\n",
    "\n",
    "                        elif type(j) == list:\n",
    "                            for item in j:\n",
    "                                nj = {}\n",
    "                                try:\n",
    "                                    for k,v in item.items():\n",
    "                                        if type(v) == list or type(v) == dict:\n",
    "                                            if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                                items.append((lj[0],None,re.sub(self._regex, '', k),v,lj[4]))\n",
    "                                        else:\n",
    "                                            nj[re.sub(self._regex, '', k)]=v\n",
    "                                            nj[self.idTable] = lj[0]\n",
    "                                            if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                                nj[self.partition] = lj[4]\n",
    "\n",
    "                                    self.listTable.append((lj[2],nj))\n",
    "                                except AttributeError as error:\n",
    "                                    _str = \"\"\n",
    "                                    for item in lj[3]:\n",
    "                                        _str = _str+str(item)+\"|\"\n",
    "\n",
    "                                    nj[self.idTable] = lj[0]\n",
    "                                    nj[lj[2]] = _str[:len(_str)-1]\n",
    "                                    if self.partition != \"\" and self.partitionReferenceColumn != \"\":\n",
    "                                                nj[self.partition] = lj[4]\n",
    "                                    self.listTable.append((lj[2],nj))\n",
    "\n",
    "                if len(items) > 0:\n",
    "                    parseJson(None,items)\n",
    "            except Exception as e:\n",
    "                print(item)\n",
    "                strError = 'Error in parseJson(): '+str(e)\n",
    "                strError = strError.replace(\"'\",\"\")\n",
    "                raise Exception(strError)\n",
    "\n",
    "        parseJson(_json)\n",
    "\n",
    "    def refineTables(self):\n",
    "        try:\n",
    "            listaTB = self.listTable\n",
    "            listNmTb = []\n",
    "\n",
    "            for l in listaTB:\n",
    "                if type(l[1]) == list:\n",
    "                    self.listRefineTables.append((l))\n",
    "\n",
    "            for tb in self.listRefineTables:\n",
    "                listaTB.remove(tb) \n",
    "\n",
    "            for tb in listaTB:\n",
    "                listNmTb.append(tb[0])\n",
    "\n",
    "            listNmTb = list(dict.fromkeys(listNmTb))\n",
    "\n",
    "            for nmTb in listNmTb:\n",
    "                tb=[]\n",
    "                for ltb in listaTB:\n",
    "                    if ltb[0] == nmTb:\n",
    "                        tb.append(ltb[1])\n",
    "                self.listRefineTables.append((nmTb,tb))\n",
    "        except Exception as e:\n",
    "            strError = 'Error in refineTables(): '+str(e)\n",
    "            strError = strError.replace(\"'\",\"\")\n",
    "            raise Exception(strError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = None\n",
    "with open('vendas-fgpinheiros-grandcru.json','r') as f:\n",
    "    j = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"C:/Users/danielfo/Documents/ZeDelivery/workspace/genericAPIConsumer/teste.json\",'r' ) as f:\n",
    "    j = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"partition\":\"\",\n",
    "    \"partitionReferenceColumn\":\"\",\n",
    "    \"idTable\":\"id\",\n",
    "    \"principalTableName\":\"tbpessoal\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del e\n",
    "e = ExplodeJson(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.recursiveParseJson(json.loads(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.refineTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbpessoal\n",
      "funcionario\n",
      "itens\n",
      "pagamentos\n",
      "body\n",
      "ecf\n",
      "cancelamento\n"
     ]
    }
   ],
   "source": [
    "for tb in e.listRefineTables:\n",
    "    print(tb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tb in e.listRefineTables:\n",
    "    if \"litaItens\" in tb[0]:\n",
    "        print(tb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tb in e.listRefineTables:\n",
    "    df = spark.sparkContext.parallelize(tb[1]).map(lambda x: json.dumps(x))\n",
    "    df = spark.read.json(df)\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(\"C:/zedelivery/ccr/\"+tb[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"C:/zedelivery/ccr/litaItens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"parquet\").load(\"C:/zedelivery/ccr/telefones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(df1, (df.id == df1.id)).drop(df1.id).where(\"id=1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in j.items():\n",
    "    for a in v:\n",
    "        print(json.loads(a.get('body')).get('id'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
